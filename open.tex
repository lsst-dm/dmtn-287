\section{Open Issues} \label{sec:open}

We have not yet tested the client server butler between SLAC and Google.
We have checked the bandwidth and latency is acceptable but it remains to be seen how it will work under the load of 10,000 users on day one of a data release.

Butler implements a client cache  so a scientists notebook or script  repeatedly accessing the same image will be well handled.
But for the cloud connections we consider a general cache for images,  this would only work if many scientists use the same image.
We do not know the image access patterns that will occur in operations and hence are not sure if this will work or perhaps the client cache is adequate.
We are considering permanently caching the deep coadds in the cloud since they will be accessed most frequently.
Individual processed visit images may well never be amenable to caching.

We need to investigate how to get a  consolidated view of key metrics and monitoring across the cloud and on-premise.
Such a view would help immensely in tracking down issues which may appear in one part while the cause is elsewhere.

For user batch we have specified users would have to have SLAC accounts and log in to SLAC to submit jobs \cite{DMTN-223} on SLAC systems.
It would be user-friendly to allow submission of batch jobs directly from the cloud-hosted science platform to these systems.
In principle we can do this however there are issues ranging from time allocation at SLAC to accessing of results which are not yet resolved.
