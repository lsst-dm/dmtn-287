\section{Open Issues} \label{sec:open}

We have not yet tested the client server butler between SLAC and Google.
We have checked the bandwidth and latency is acceptable but it remains to be seen how it will work under the load of 10,000 users on day one of a data release.

Butler implements a client cache so a scientist's notebook or script repeatedly accessing the same image is read efficiently.
For cloud connections, we consider a general cache for images, but this would only work if many scientists use the same image.
We do not know the image access patterns that will occur in operations, so we are unsure if this will work. Perhaps the client cache is adequate.
We are considering permanently caching the deep coadds in the cloud since they will be accessed most frequently.
Individual processed visit images may never be amenable to caching.

We need to investigate how to get a  consolidated view of key metrics and monitoring across the cloud and on-premise.
Such a view would help immensely in tracking down issues which may appear in one part while the cause is elsewhere.

For user batch we have specified users would have to have SLAC accounts and log in to SLAC to submit jobs \cite{DMTN-223} on SLAC systems.
It would be user-friendly to allow submission of batch jobs directly from the cloud-hosted science platform to these systems.
In principle we can do this however there are issues ranging from time allocation at SLAC to accessing of results which are not yet resolved.
